##Working directory
setwd("D:/Research/ML regression")
getwd()

##Required libraries
library(readxl)
library(dplyr)
library(xgboost)
library(SHAPforxgboost)
library(caret)
library(ggplot2)
library(MLmetrics)

##Upload the data file
data<-read_excel("data_denV.xlsx")
head(data)
str(data)

#Data split
#80% of the sample size
smp_size<-floor(0.8 * nrow(data))
print(smp_size)
## set the seed to make partition reproducible
set.seed(123)
train_ind <-sample(seq_len(nrow(data)),size = smp_size)
train<-data[1:smp_size,]
test <-data[smp_size+1:nrow(data),]
test<-na.omit(test)

##Linear regression
#Model metrics
control <-trainControl(method="cv",
                       number=10)
metric <- "RMSE"

##Model fitting
fit.mlr<-train(Female~., data=train, method="lm", metric=metric, trControl=control)
fit.mlr

#prediction in training
pre<-predict(fit.mlr,train)
mape<-MAPE(train$Female,pre)

#Model prediction
pred1<-predict(fit.mlr,test)
mse<-mean((test$Female-pred1)^2)
rmse<-sqrt(mse)
mae<-mean(abs(test$Female-pred1))
MAPE(test$Female,pred1)


##Random forest model
#Model metrics
control <-trainControl(method="cv",
                       number=5)

##Model fitting
fit.rf<-train(Female~., data=train, method="rf", metric=metric, trControl=control)
fit.rf

#prediction in training
pre2<-predict(fit.rf,train)
mape<-MAPE(train$Female,pre2)

#Model prediction
pred2<-predict(fit.rf,test)
mse<-mean((test$Female-pred2)^2)
rmse<-sqrt(mse)
mae<-mean(abs(test$Female-pred2))
MAPE(test$Female,pred2)

##XGBoost model
dtrain<-xgb.DMatrix(data=as.matrix(train[c(1:2,4:45)]),label=train$Female)
dtest<-xgb.DMatrix(data=as.matrix(test[c(1:2,4:45)]),label=test$Female)

# XGBoost parameters: This hyper-parameters set is tuned one
params.xgb <- list(booster = "gbtree", 
                   objective = "reg:squarederror", 
                   eta =0.1, 
                   gamma=1, 
                   min_child_weight = 5,# ,
                   lambda=1 )
# xgb corss-validation train
xgbcv <- xgb.cv(params =  params.xgb, 
                data = dtrain, 
                nrounds = 1000, 
                nfold = 5, 
                showsd = F,
                prediction = T,
                stratified = T, 
                print_every_n = 1, 
                early_stopping_rounds = 30, 
                maximize = F
)
#' Final training and metrics evaluation on test sets
set.seed(1)
watchlist = list( test = dtest,
                  train = dtrain) 
model.xgb <- xgb.train(params = params.xgb, 
                       data = dtrain, 
                       nrounds =  24,   
                       watchlist = watchlist, 
                       print_every_n = 1, 
                       early_stopping_rounds =30, 
                       maximize = F
)


#Prediction in training set
pre3<-predict(model.xgb,dtrain)
mse<-mean((train$Female-pre3)^2)
sqrt(mse)
mae<-mean(abs(train$Female-pre3))
mape<-MAPE(train$Female,pre3)

#Model prediction
pred3<-predict(model.xgb,dtest)
mse<-mean((test$Female-pred3)^2)
sqrt(mse)
mae<-mean(abs(test$Female-pred3))
MAPE(test$Female,pred3)

#Decision Tree model
#Model metrics
control <-trainControl(method="cv",
                       number=15)
metric <- "RMSE"

##Model fitting
fit.dt<-train(Female~., data=train, method="rpart", metric=metric, trControl=control)
fit.dt

#Prediction in training set
pre4<-predict(fit.dt,train)
mape<-MAPE(train$Female,pre4)

#Model prediction
pred4<-predict(fit.dt,test)
mse<-mean((test$Female-pred4)^2)
sqrt(mse)
mae<-mean(abs(test$Female-pred4))
MAPE(test$Female,pred4)

#Feature importance using mean |SHAP| values for XGBoost model as best
shap_values <- shap.values(xgb_model = model.xgb, X_train = dtrain)
shap_values$mean_shap_score

#plot
data2<-read_excel("xgb.mean.shap.xlsx");data2
fig1<-ggplot(data2,aes(x=SHAP,y=reorder(Features,SHAP),fill=Features))+
  geom_bar(stat="identity",position = "dodge")+theme(text = element_text(size=18))+
  theme_set(theme_bw()+theme(legend.position ="none"))+
  ggtitle("")+xlab("mean |SHAP|")+ylab("Features")
fig1
